---
title: "Assignment 1 - Data Analysis 3"
author: "David Utassy"
date: "02/02/2021"
output: 
  html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r includes, include=FALSE, cache=TRUE}
#########################################################################################
# Prepared for David Utassy's DA3 assignment 1.
#
#########################################################################################



# ------------------------------------------------------------------------------------------------------
#### SET UP
rm(list=ls())


library(rattle)
library(tidyverse)
library(caret)
library(ranger)
library(Hmisc)
library(knitr)
library(kableExtra)
library(xtable)


data_in <- "/Users/utassydv/Documents/workspaces/CEU/my_repos/data_analysis_prediction/airbnb_tokyo/data/clean/airbnb_tokio_cleaned.csv"
data_out <- ""
output <- "/Users/utassydv/Documents/workspaces/CEU/my_repos/data_analysis_prediction/airbnb_tokyo/out/"
#-----------------------------------------------------------------------------------------

#########################################################################################
#
# PART I
# Loading and preparing data ----------------------------------------------
#
#########################################################################################

data <- read_csv(data_in) %>%
  mutate_if(is.character, factor) %>%
  filter(!is.na(usd_price_day))


count_missing_values <- function(data) {
  num_missing_values <- map_int(data, function(x) sum(is.na(x)))
  num_missing_values[num_missing_values > 0]
}

count_missing_values(data)

# Sample definition and preparation ---------------------------------------

# We focus on normal apartments, 2<n<6

table(data$f_property_type)
data <- data %>% filter(f_property_type == "Apartment")
#data <- data %>% filter(f_room_type == "Entire home/apt")

data <- data %>% filter(n_accommodates <= 6 & n_accommodates >= 2)

# copy a variable - purpose later, see at variable importance
data <- data %>% mutate(n_accommodates_copy = n_accommodates)

# basic descr stat -------------------------------------------
#skimr::skim(data)
summary(data$usd_price_day)
Hmisc::describe(data$usd_price_day)
describe(data$f_room_type)
describe(data$f_property_type)
table(data$f_number_of_reviews)

# create train and holdout samples -------------------------------------------
# train is where we do it all, incl CV

set.seed(2801)

# First pick a smaller than usual training set so that models run faster and check if works
# If works, start anew without these two lines

#try <- createDataPartition(data$usd_price_day, p = 0.2, list = FALSE)
#data <- data[try, ]



train_indices <- as.integer(createDataPartition(data$price, p = 0.7, list = FALSE))
data_train <- data[train_indices, ]
data_holdout <- data[-train_indices, ]

dim(data_train)
dim(data_holdout)

# Define models: simpler, extended -----------------------------------------------------------

# Basic Variables inc neighnourhood
basic_vars <- c(
  "n_accommodates", "n_beds", "n_days_since", "f_neighbourhood_cleansed", "f_room_type")

# reviews
reviews <- c("n_number_of_reviews", "flag_n_number_of_reviews" ,"n_review_scores_rating", "flag_review_scores_rating")

# Dummy variables
amenities <-  grep("^d_.*", names(data), value = TRUE)

#interactions for the LASSO
#TODO: do something about it

# with boroughs
X1  <- c("f_room_type*f_neighbourhood_cleansed", "f_room_type*f_neighbourhood_cleansed",
         "n_accommodates*f_neighbourhood_cleansed", "d_elevator*f_neighbourhood_cleansed")


predictors_1 <- c(basic_vars, reviews)
predictors_2 <- c(basic_vars, reviews, amenities)
predictors_E <- c(basic_vars, reviews, amenities, X1)


#########################################################################################
#
# PART II
# RANDOM FORESTS -------------------------------------------------------
#
#########################################################################################



# do 5-fold CV
train_control <- trainControl(method = "cv",
                              number = 5,
                              verboseIter = FALSE)


# set tuning
tune_grid <- expand.grid(
  .mtry = c(3,4,5),               #controlling complexity of individual trees, number of features used at splitting sqrt(features)
  .splitrule = "variance",
  .min.node.size = c(5, 10)       #min num observations in the terminating nodes
)
```

```{r price_dist_plot_create, include=FALSE, cache=TRUE}
price_dist<- ggplot( data , aes( x = usd_price_day ) ) +
    geom_histogram( aes(y = ..density..) , alpha = 1, binwidth = 5, color = 'black', fill = "#3a5e8cFF") +
    geom_density( aes(y = ..density..) , alpha = .2 , bw = 5, color = 'black', fill="#FF6666") +
    labs(x='Price (USD)',y='Density')
```

```{r rf_models, include=FALSE, cache=TRUE}
# simpler model for model A (1)
set.seed(1234)
system.time({
  rf_model_1 <- train(
    formula(paste0("usd_price_day ~", paste0(predictors_1, collapse = " + "))),
    data = data_train,
    method = "ranger",
    trControl = train_control,
    tuneGrid = tune_grid,
    importance = "impurity"
  )
})
rf_model_1
write.csv(rf_model_1$results, paste0(output, "rf_model_1.csv"), row.names = F)

# set tuning for benchamrk model (2)
tune_grid <- expand.grid(
  .mtry = c(5, 7, 9),
  .splitrule = "variance",
  .min.node.size = c(5, 10, 15)
)

set.seed(1234)
system.time({
  rf_model_2 <- train(
    formula(paste0("usd_price_day ~", paste0(predictors_2, collapse = " + "))),
    data = data_train,
    method = "ranger",
    trControl = train_control,
    tuneGrid = tune_grid,
    importance = "impurity"
  )
})

rf_model_2
write.csv(rf_model_2$results, paste0(output, "rf_model_2.csv"), row.names = F)

#auto tuning first
#set.seed(1234)
#system.time({
#  rf_model_2auto <- train(
#    formula(paste0("usd_price_day ~", paste0(predictors_2, collapse = " + "))),
#    data = data_train,
#    method = "ranger",
#    trControl = train_control,
#    importance = "impurity"
#  )
#})
#rf_model_2auto 
#rf_model_2auto <-rf_model_2
#write.csv(rf_model_2auto$results, paste0(output, "rf_model_2auto.csv"), row.names = F)
```


```{r rf_results, include=FALSE, cache=TRUE}
# evaluate random forests -------------------------------------------------

results <- resamples(
  list(
    model_1  = rf_model_1,
    model_2  = rf_model_2
    #model_2b = rf_model_2auto
    
  )
)
summary(results)

# Save outputs -------------------------------------------------------

# Show Model B rmse shown with all the combinations
rf_tuning_modelB <- rf_model_2$results %>%
  dplyr::select(mtry, min.node.size, RMSE) %>%
  dplyr::rename(nodes = min.node.size) %>%
  spread(key = mtry, value = RMSE)

kable(x = rf_tuning_modelB, format = "latex", digits = 2, caption = "CV RMSE") %>%
  add_header_above(c(" ", "vars" = 3)) %>%
  cat(.,file="/Users/utassydv/Documents/workspaces/CEU/my_repos/data_analysis_prediction/airbnb_tokyo/out/rf_tuning_modelB.tex")
write.csv(rf_tuning_modelB, paste0(output, "rf_tuning_modelB.csv"), row.names = F)

# Turning parameter choice 1
result_1 <- matrix(c(
  rf_model_1$finalModel$mtry,
  rf_model_2$finalModel$mtry,
  rf_model_1$finalModel$min.node.size,
  rf_model_2$finalModel$min.node.size
  
),
nrow=2, ncol=2,
dimnames = list(c("Model A", "Model B"),
                c("Min vars","Min nodes"))
)
kable(x = result_1, format = "latex", digits = 3) %>%
  cat(.,file="/Users/utassydv/Documents/workspaces/CEU/my_repos/data_analysis_prediction/airbnb_tokyo/out/rf_models_turning_choices.tex")
write.csv(result_1, paste0(output, "rf_parameter_selection.csv"), row.names = T)

# Turning parameter choice 2
result_2 <- matrix(c(mean(results$values$`model_1~RMSE`),
                     mean(results$values$`model_2~RMSE`)
),
nrow=2, ncol=1,
dimnames = list(c("Model A", "Model B"),
                c(results$metrics[2]))
)


kable(x = result_2, format = "latex", digits = 3) %>%
  cat(.,file="/Users/utassydv/Documents/workspaces/CEU/my_repos/data_analysis_prediction/airbnb_tokyo/out/rf_models_rmse.tex")
write.csv(result_2, paste0(output, "rf_models_compare.csv"), row.names = T)

#########################################################################################
#
# PART III
# MODEL DIAGNOSTICS -------------------------------------------------------
#
#########################################################################################


#########################################################################################
# Variable Importance Plots -------------------------------------------------------
#########################################################################################
# first need a function to calculate grouped varimp
group.importance <- function(rf.obj, groups) {
  var.imp <- as.matrix(sapply(groups, function(g) {
    sum(importance(rf.obj)[g], na.rm = TRUE)
  }))
  colnames(var.imp) <- "MeanDecreaseGini"
  return(var.imp)
}


# variable importance plot
# 1) full varimp plot, full
# 2) varimp plot grouped
# 3) varimp plot , top 10
# 4) varimp plot  w copy, top 10


rf_model_2_var_imp <- importance(rf_model_2$finalModel)/1000
rf_model_2_var_imp_df <-
  data.frame(varname = names(rf_model_2_var_imp),imp = rf_model_2_var_imp) %>%
  mutate(varname = gsub("f_neighbourhood_cleansed", "Borough:", varname) ) %>%
  mutate(varname = gsub("f_room_type", "Room type:", varname) ) %>%
  arrange(desc(imp)) %>%
  mutate(imp_percentage = imp/sum(imp))
write.csv(rf_model_2_var_imp_df, paste0(output, "rf_model_2_var_imp_df.csv"), row.names = F)


##############################
# 1) full varimp plot, above a cutoff
##############################

# to have a quick look
plot(varImp(rf_model_2))
#TODO continue
source("/Users/utassydv/Documents/workspaces/CEU/my_repos/data_analysis_prediction/airbnb_tokyo/theme_bg.R")
cutoff = 600
rf_model_2_var_imp_plot <- ggplot(rf_model_2_var_imp_df[rf_model_2_var_imp_df$imp>cutoff,],
                                  aes(x=reorder(varname, imp), y=imp_percentage)) +
  geom_point(color=color[1], size=1.5) +
  geom_segment(aes(x=varname,xend=varname,y=0,yend=imp_percentage), color=color[1], size=1) +
  ylab("Importance (Percent)") +
  xlab("Variable Name") +
  coord_flip() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_bg() +
  theme(axis.text.x = element_text(size=6), axis.text.y = element_text(size=6),
        axis.title.x = element_text(size=6), axis.title.y = element_text(size=6))
rf_model_2_var_imp_plot
#save_fig("rf_varimp1",output, "large")
#save_fig("ch16-figure-1-rf-varimp-base",output, "large")

##############################
# 2) full varimp plot, top 10 only
##############################


# have a version with top 10 vars only
rf_model_2_var_imp_plot_b <- ggplot(rf_model_2_var_imp_df[1:10,], aes(x=reorder(varname, imp), y=imp_percentage)) +
  geom_point(color=color[1], size=1) +
  geom_segment(aes(x=varname,xend=varname,y=0,yend=imp_percentage), color=color[1], size=0.75) +
  ylab("Importance (Percent)") +
  xlab("Variable Name") +
  coord_flip() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_bg() +
  theme(axis.text.x = element_text(size=4), axis.text.y = element_text(size=4),
        axis.title.x = element_text(size=4), axis.title.y = element_text(size=4))
rf_model_2_var_imp_plot_b
#save_fig("rf_varimp1_b",output, "small")
#save_fig("ch16-figure-2b-rf-varimp-top10",output, "small")


##############################
# 2) varimp plot grouped
##############################
# grouped variable importance - keep binaries created off factors together

varnames <- rf_model_2$finalModel$xNames
f_neighbourhood_cleansed_varnames <- grep("f_neighbourhood_cleansed",varnames, value = TRUE)
f_cancellation_policy_varnames <- grep("f_cancellation_policy",varnames, value = TRUE)
f_bed_type_varnames <- grep("f_bed_type",varnames, value = TRUE)
f_property_type_varnames <- grep("f_property_type",varnames, value = TRUE)
f_room_type_varnames <- grep("f_room_type",varnames, value = TRUE)

groups <- list(f_neighbourhood_cleansed=f_neighbourhood_cleansed_varnames,
               f_room_type = f_room_type_varnames,
               n_days_since = "n_days_since",
               n_accommodates = "n_accommodates",
               n_beds = "n_beds",
               n_number_of_reviews = "n_number_of_reviews",
               n_review_scores_rating = "n_review_scores_rating",
               d_elevator = "d_elevator",
               d_cookingbasics = "d_cookingbasics",
               d_tv = "d_tv",
               d_keypad = "d_keypad",
               d_dryer = "d_dryer",
               d_lockbox = "d_lockbox"
               
)

rf_model_2_var_imp_grouped <- group.importance(rf_model_2$finalModel, groups)
rf_model_2_var_imp_grouped_df <- data.frame(varname = rownames(rf_model_2_var_imp_grouped),
                                            imp = rf_model_2_var_imp_grouped[,1])  %>%
  mutate(imp_percentage = imp/sum(imp))
write.csv(rf_model_2_var_imp_grouped, paste0(output, "rf_model_2_var_imp_grouped_df.csv"), row.names = T)

rf_model_2_var_imp_grouped_plot <-
  ggplot(rf_model_2_var_imp_grouped_df, aes(x=reorder(varname, imp), y=imp_percentage)) +
  geom_point(color=color[1], size=1) +
  geom_segment(aes(x=varname,xend=varname,y=0,yend=imp_percentage), color=color[1], size=0.7) +
  ylab("Importance (Percent)") +   xlab("Variable Name") +
  coord_flip() +
  # expand=c(0,0),
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_bg() +
  theme(axis.text.x = element_text(size=10), axis.text.y = element_text(size=10),
        axis.title.x = element_text(size=10), axis.title.y = element_text(size=10))
rf_model_2_var_imp_grouped_plot
save_fig("rf_varimp_grouped1",output, "large")
#save_fig("ch16-figure-2a-rf-varimp-group",output, "small")



#########################################################################################
# Partial Dependence Plots -------------------------------------------------------
#########################################################################################

# TODO
# : somehow adding scale screws up. ideadlly both graphs y beween 70 and 130,
# n:accom should be 1,7 by=1

# FIXME
# should be on holdout, right? pred.grid = distinct_(data_train, "), --> pred.grid = distinct_(data_holdout, )

pdp_n_acc <- pdp::partial(rf_model_2, pred.var = "n_accommodates", pred.grid = distinct_(data_holdout, "n_accommodates"), train = data_train)
pdp_n_acc_plot <- pdp_n_acc %>%
  autoplot( ) +
  geom_point(color=color[1], size=2) +
  geom_line(color=color[1], size=1) +
  ylab("Predicted price") +
  xlab("Accommodates (persons)") +
  scale_x_continuous(limit=c(1,7), breaks=seq(1,7,1))+
  theme_bg()+
  theme(axis.text.x = element_text(size=10), axis.text.y = element_text(size=10),
        axis.title.x = element_text(size=10), axis.title.y = element_text(size=10))
pdp_n_acc_plot
save_fig("rf_pdp_n_accom", output, "large")
#save_fig("ch16-figure-3a-rf-pdp-n-accom", output, "small")


pdp_n_roomtype <- pdp::partial(rf_model_2, pred.var = "f_room_type", pred.grid = distinct_(data_holdout, "f_room_type"), train = data_train)
pdp_n_roomtype_plot <- pdp_n_roomtype %>%
  autoplot( ) +
  geom_point(color=color[1], size=2) +
  ylab("Predicted price") +
  xlab("Room type") +
  scale_y_continuous(limits=c(60,120), breaks=seq(60,120, by=10)) +
  theme_bg()
pdp_n_roomtype_plot
#save_fig("rf_pdp_roomtype", output, "small")
#save_fig("ch16-figure-3b-rf-pdp-roomtype", output, "small")

pdp_n_borough <- pdp::partial(rf_model_2, pred.var = "f_neighbourhood_cleansed", pred.grid = distinct_(data_holdout, "f_neighbourhood_cleansed"), train = data_train)
pdp_n_borough_plot <- pdp_n_borough %>%
  autoplot( ) +
  geom_point(color=color[1], size=2) +
  ylab("Predicted price") +
  xlab("Borough") +
  scale_y_continuous(limits=c(60,120), breaks=seq(60,120, by=10)) +
  theme_bg() +
  theme(axis.text.x = element_text(angle = 90))+
  theme(axis.text.x = element_text(size=10), axis.text.y = element_text(size=10),
        axis.title.x = element_text(size=10), axis.title.y = element_text(size=10))
pdp_n_borough_plot
save_fig("rf_pdp_n_borough_plot", output, "large")
# Subsample performance: RMSE / mean(y) ---------------------------------------
# NOTE  we do this on the holdout set.

# ---- cheaper or more expensive flats - not used in book
data_holdout_w_prediction <- data_holdout %>%
  mutate(predicted_price = predict(rf_model_2, newdata = data_holdout))



######### create nice summary table of heterogeneity
a <- data_holdout_w_prediction %>%
  mutate(is_low_size = ifelse(n_accommodates <= 3, "small apt", "large apt")) %>%
  group_by(is_low_size) %>%
  dplyr::summarise(
    rmse = RMSE(predicted_price, usd_price_day),
    mean_price = mean(usd_price_day),
    rmse_norm = RMSE(predicted_price, usd_price_day) / mean(usd_price_day)
  )
a

b <- data_holdout_w_prediction %>%
  filter(f_neighbourhood_cleansed %in% c("Fuchu Shi", "Kokubunji Shi", "Hino Shi")) %>%
  group_by(f_neighbourhood_cleansed) %>%
  dplyr::summarise(
    rmse = RMSE(predicted_price, usd_price_day),
    mean_price = mean(usd_price_day),
    rmse_norm = rmse / mean_price
  )
b
c <- data_holdout_w_prediction %>%
  group_by(f_room_type) %>%
  dplyr::summarise(
    rmse = RMSE(predicted_price, usd_price_day),
    mean_price = mean(usd_price_day),
    rmse_norm = rmse / mean_price
  )


d <- data_holdout_w_prediction %>%
  dplyr::summarise(
    rmse = RMSE(predicted_price, usd_price_day),
    mean_price = mean(usd_price_day),
    rmse_norm = RMSE(predicted_price, usd_price_day) / mean(usd_price_day)
  )

# Save output
colnames(a) <- c("", "RMSE", "Mean price", "RMSE/price")
colnames(b) <- c("", "RMSE", "Mean price", "RMSE/price")
colnames(c) <- c("", "RMSE", "Mean price", "RMSE/price")
d<- cbind("All", d)
colnames(d) <- c("", "RMSE", "Mean price", "RMSE/price")

line1 <- c("Apartment size", "", "", "")
line2 <- c("Borough", "", "", "")
line3 <- c("Room type", "", "", "")

result_3 <- rbind(line1, a, line3, c, line2, b, d) %>%
  transform(RMSE = as.numeric(RMSE), `Mean price` = as.numeric(`Mean price`),
            `RMSE/price` = as.numeric(`RMSE/price`))

options(knitr.kable.NA = '')
kable(x = result_3, format = "latex", booktabs=TRUE, linesep = "",digits = c(0,2,1,2), col.names = c("","RMSE","Mean price","RMSE/price")) %>%
  cat(.,file= paste0(output, "performance_across_subsamples.tex"))
options(knitr.kable.NA = NULL)
write.csv(result_3, paste0(output,"normalized_rmse.csv"), row.names = F)

##########################################
```

```{r horse_race, include=FALSE, cache=TRUE}
#########################################################################################
#
# PART IV
# HORSERACE: compare with other models -----------------------------------------------
#
#########################################################################################



# OLS with dummies for area
# using model B

set.seed(1234)
system.time({
  ols_model <- train(
    formula(paste0("usd_price_day ~", paste0(predictors_1, collapse = " + "))),
    data = data_train,
    method = "lm",
    trControl = train_control
  )
})

ols_model_coeffs <-  ols_model$finalModel$coefficients
ols_model_coeffs_df <- data.frame(
  "variable" = names(ols_model_coeffs),
  "ols_coefficient" = ols_model_coeffs
) %>%
  mutate(variable = gsub("`","",variable))
write.csv(ols_model_coeffs_df, paste0(output,"ols_model_coeffs_df.csv"), row.names = F)

# * LASSO
# using extended model w interactions

set.seed(1234)
system.time({
  lasso_model <- train(
    formula(paste0("usd_price_day ~", paste0(predictors_E, collapse = " + "))),
    data = data_train,
    method = "glmnet",
    preProcess = c("center", "scale"),
    tuneGrid =  expand.grid("alpha" = 1, "lambda" = seq(0.01, 0.25, by = 0.01)),
    trControl = train_control
  )
})

lasso_coeffs <- coef(
  lasso_model$finalModel,
  lasso_model$bestTune$lambda) %>%
  as.matrix() %>%
  as.data.frame() %>%
  rownames_to_column(var = "variable") %>%
  rename(lasso_coefficient = `1`)  # the column has a name "1", to be renamed

lasso_coeffs_non_null <- lasso_coeffs[!lasso_coeffs$lasso_coefficient == 0,]

regression_coeffs <- merge(ols_model_coeffs_df, lasso_coeffs_non_null, by = "variable", all=TRUE)
regression_coeffs %>%
  write.csv(file = paste0(output, "regression_coeffs.csv"), row.names = F)

# CART
set.seed(1234)
system.time({
  cart_model <- train(
    formula(paste0("usd_price_day ~", paste0(predictors_2, collapse = " + "))),
    data = data_train,
    method = "rpart",
    tuneLength = 10,
    trControl = train_control
  )
})
```

```{r treeplot, include=FALSE, cache=TRUE}
cart_tree <- fancyRpartPlot(cart_model$finalModel, sub = "")
#save_fig(cart_tree,"cart_tree", output, "large")
```

```{r gbm_model, include=FALSE, cache=TRUE}
# GBM  -------------------------------------------------------
gbm_grid <-  expand.grid(interaction.depth = c(1, 5, 10), # complexity of the tree
                         n.trees = (4:10)*50, # number of iterations, i.e. trees
                         shrinkage = 0.1, # learning rate: how quickly the algorithm adapts
                         n.minobsinnode = 20 # the minimum number of training set samples in a node to commence splitting
)


set.seed(1234)
system.time({
  gbm_model <- train(formula(paste0("usd_price_day ~", paste0(predictors_2, collapse = " + "))),
                     data = data_train,
                     method = "gbm",
                     trControl = train_control,
                     verbose = FALSE,
                     tuneGrid = gbm_grid)
})
gbm_model


# much more tuning

#  faster, for testing
#gbm_grid2 <-  expand.grid(interaction.depth = c( 5, 7, 9, 11), # complexity of the tree
#                          n.trees = (1:10)*50, # number of iterations, i.e. trees
#                          shrinkage = c(0.05, 0.1), # learning rate: how quickly the algorithm adapts
#                          n.minobsinnode = c(10,20) # the minimum number of training set samples in a node to commence splitting
#)


# the next will be in final model, loads of tuning
#gbm_grid2 <-  expand.grid(interaction.depth = c(1, 3, 5, 7, 9, 11), # complexity of the tree
#                          n.trees = (1:10)*50, # number of iterations, i.e. trees
#                          shrinkage = c(0.02, 0.05, 0.1, 0.15, 0.2), # learning rate: how quickly the algorithm adapts
#                          n.minobsinnode = c(5,10,20,30) # the minimum number of training set samples in a node to commence splitting
#)
# !!!THIS model is tested, not giving a better result than RF, and takes hours to run!!!

#set.seed(1234)
#system.time({
#  gbm_model2 <- train(formula(paste0("usd_price_day ~", paste0(predictors_2, collapse = " + "))),
#                      data = data_train,
#                      method = "gbm",
#                      trControl = train_control,
#                      verbose = FALSE,
#                      tuneGrid = gbm_grid2)
#})
#gbm_model2


# and get prediction rmse and add to next summary table
```

```{r end_res, include=FALSE, cache=TRUE}
# ---- compare these models

final_models <-
  list("OLS" = ols_model,
       "LASSO (model w/ interactions)" = lasso_model,
       "CART" = cart_model,
       "Random forest (smaller model)" = rf_model_1,
       "Random forest" = rf_model_2,
       "GBM (basic tuning)"  = gbm_model)

results <- resamples(final_models) %>% summary()


# Save output --------------------------------------------------------
# Model selection is carried out on this CV RMSE

result_4 <- imap(final_models, ~{
  mean(results$values[[paste0(.y,"~RMSE")]])
}) %>% unlist() %>% as.data.frame() %>%
  rename("CV RMSE" = ".")

kable(x = result_4, format = "html", digits = 3, booktabs=TRUE, linesep = "") %>%
  cat(.,file= paste0(output,"horse_race_of_models_cv_rmse.html"))
write.csv(result_4, paste0(output, "horse_race_of_models_cv_rmse.csv"), row.names = TRUE)
          



# evaluate preferred model on the holdout set -----------------------------

result_5 <- map(final_models, ~{
  RMSE(predict(.x, newdata = data_holdout), data_holdout[["usd_price_day"]])
}) %>% unlist() %>% as.data.frame() %>%
  rename("Holdout RMSE" = ".")

kable(x = result_5, format = "latex", digits = 3, booktabs=TRUE, linesep = "") %>%
  cat(.,file= paste0(output,"horse_race_of_models_houldout_rmse.tex"))
write.csv(result_5, paste0(output, "horse_race_of_models_houldout_rmse.csv"), row.names = TRUE)
#ch16-table-1-rf-models-turning-choices
#ch16-table-2-performance-across-subsamples
#ch16-table-3-horse-race-of-models-cv-rmse

# Predicted values
predictionlev_holdout_pred <- as.data.frame(predict(rf_model_2, newdata = data_holdout, interval="predict"))
predictionlev_holdout_conf <- as.data.frame(predict(rf_model_2, newdata = data_holdout, interval="confidence"))



predictionlev_holdout <- cbind(data_holdout[,c("usd_price_day","n_accommodates")],
                               predictionlev_holdout_pred)


# Create data frame with the real and predicted values
d <- data.frame(ylev=predictionlev_holdout[,"usd_price_day"], predlev=predictionlev_holdout[,3] )
# Check the differences

# Plot predicted vs price
level_vs_pred <- ggplot(data = d) +
  geom_point(aes(y=ylev, x=predlev), color = color[1], size = 1,
             shape = 16, alpha = 0.7, show.legend=FALSE, na.rm=TRUE) +
  #geom_smooth(aes(y=ylev, x=predlev), method="lm", color=color[2], se=F, size=0.8, na.rm=T)+
  geom_segment(aes(x = 0, y = 0, xend = 350, yend =350), size=0.5, color=color[2], linetype=2) +
  coord_cartesian(xlim = c(0, 250), ylim = c(0, 250)) +
  scale_x_continuous(expand = c(0.01,0.01),limits=c(0, 350), breaks=seq(0, 350, by=50)) +
  scale_y_continuous(expand = c(0.01,0.01),limits=c(0, 350), breaks=seq(0, 350, by=50)) +
  labs(y = "Price (US dollars)", x = "Predicted price  (US dollars)") +
  theme_bg() +
  theme(axis.text.x = element_text(size=10), axis.text.y = element_text(size=10),
        axis.title.x = element_text(size=10), axis.title.y = element_text(size=10))
level_vs_pred
save_fig("ch14-figure-8a-level-vs-pred", output, "small")

```

### [GitHub repository](https://github.com/utassydv/data_analysis_prediction/tree/main/airbnb_tokyo)

# Introduction

The purpose of this writing is to document the first assignment for the course Data Analysis 3 course. 
The task was to help a company operating small and mid-sized apartments hosting 2-6 guests in Tokyo. The main goal of this project is to create a price prediction model that can be used by the company to predict the optimal price of their apartments. 

The whole analysis was written in R, and the code is available under [this GitHub repository](https://github.com/utassydv/data_analysis_prediction/tree/main/airbnb_tokyo). We can separate the code into three parts. I prepared the data mainly in the "airbnb-prepare-tokyo.R" file, then the analysis and model building is done in the "airbnb-predict-tokyo.R" file, and the "airbnb-prepare-tokyo_documentation.Rmd" file is responsible for creating this document itself. 

# Data

The dataset scraped from Airbnb and it is taken from the following website: http://insideairbnb.com/get-the-data.html. The exact source of my data is [this file](http://data.insideairbnb.com/japan/kant%C5%8D/tokyo/2020-12-29/data/listings.csv.gz) which is scraped in December 2020. Furthermore, [here](https://docs.google.com/spreadsheets/d/1iWCNJcSutYqpULSQHlNyGInUvHg2BoUGoNRIGa6Szc4/edit#gid=982310896) is a useful dictionary about the variables from the creator of the website. 

### Data validity:

As the data source is scraped from Airbnb, it means that it is kind of representative regarding apartments to rent in Tokyo, as we can state that Airbnb is big enough to provide us robust data. However, the effect of the current pandemic, and the fact, that it is planned that the Summer Olympics 2020(21) will take place in Tokyo we have several insecurities in the currently scraped data. 
Especially because of the pandemic situation, our data represents an industry that is trying to survive, and we would like to make a prediction on how to price apartments. This might tell us, that we should use a dataset, that is from the times before the pandemic hit the world, and it might be true if we are aiming to price for a “back to normal” world, but that state may never return, therefore I am making the prediction for the current “new normal” with the latest data I can have. 

As a left-hand-side variable, I choose the one night price of apartments. I would like to highlight here, that the $ sign in the provided data before each and every price, is misleading. According to the creator of http://insideairbnb.com,  and the above-linked dictionary table, all the prices are in local currency. In my case, it is Japanese Yen, however, in the favor of easier interpretation I converted it into USD. 

For predictor variables, in the end, I have included other variables from the dataset in an automated way using ML models. However, to give a glimpse here are some of the most important variables from my final model: number of people that the place can accommodate (n_accomodates), days since the first review, number of beds, number of reviews, ratings, room type, borough, and several dummy variables from different amenities stated on Airbnb.

### Data preparation

The dataset that I downloaded from insideairbnb.com contains 11353 observations. According to the main goal of my final prediction model, first of all, I filtered for apartments with possible n_accomodates between 2 and 6. That resulted in a dataset of 6106 observations. Moreover, I was needed to make some basic data cleaning such as converting strings into numerical variables, creating dummy variables from the column called amenities, imputing some missing values, and deleting observations with important missing values such as price.

Additionally, according to the histogram of price/night, and the later experience on models performing in prediction, I made the decision, to drop all observations with prices over 500 US Dollars. The originally filtered data had a very long right tail and at certain extreme price levels, there were significant (20-50) number of observations. First of all these observations were clearly not in the main pattern, additionally non of the models managed to handle those values resulting in a huge RMSE. From the points I mentioned above I assumed, that my data does not contain the reason for these extreme prices and I believe that I would need more domain knowledge to handle those observations. At the end of data preparation, I ended up with 5926 observations. In the following graph, the reader can observe the price distribution of apartments I used to train my models on. It is still right-skewed (as it should be) with some extreme values. 

```{r price_dist_plot, fig.width=8,fig.height=4, fig.align='center', echo = FALSE , results = 'asis', warning = FALSE, message = FALSE}
price_dist
```

# Model building

To get a great prediction model, I have created 5 different types of models. My goal was to experiment with ML models such as Random Forest and Gradient Boosting Machines but as a benchmark, I created models like OLS, LASSO, and CART. 
In order to compare the models, I divided the data into a training (4900) and a holdout (1026) data-set. Additionally, it is important to mention that I used 5 fold cross-validation in each training of the model on the training dataset. 

### OLS:

I believe that it is not the best possible OLS model for this prediction. To get a better model I should have done more exploratory data analysis, searching for associations between y and each x variables. However, in order to avoid spending a significant amount of time on creating a better OLS model, I created a simple and robust one, the have a great benchmark for my other models.

I have used the following variables:
basic:

- n_accomodates (possible number of people in the apartment)
- n_beds (number of beds
- n_days_since (number of days since the first review)
- f_neighbbourhood_cleansed (dummy variables on boroughs)
- f_room_type (categorical variable entire apartment or private/shared room)

review related:

- f_number_of_reviews (number of reviews on the apartment)
- flag_n_number_of_reviews (whether the variable is imputed or not)
- n_review_scores_rating (rating scores)
- flag_review_scores_rating (whether the variable is imputed or not)

I will share the goodness of this model later in the model selection part.

### LASSO:

With to OLS, the complicated part is to choose which variables should be included in the model and how should we include them, therefore it worth using LASSO. LASSO selects some of the candidate x variables to remain in the regression in an automated way. I just had to provide it a set of variables. Additionally to the ones that I used in the OLS, I provided the dummy variables created from the amenities column and added some interaction terms as well. 

I will share the goodness of this model later in the model selection part.

### CART

To start with the less important, I would like to mention that I ran a CART model with a complexity parameter of 10. We do not expect a good result from this method, but I will introduce its results in the model selection part.

### Random Forest

One of the most promising model was Random Forest. I ran two different models, a simpler and a more complex one regarding the variables provided to them. I used the caret library to train these models and used a tuning grid with each of them to find better tuning parameters. 
For the simpler model, I provided 9 and for the more complex one, I provided 54 variables. In the tuning grid, I used numbers according to the rule of thumb (square root of variables) on the number of possible variables in each split. Also, I used 5, 10, 15 as a minimum nodes parameter. 

### Gradient Boosting Machines

The other promising model is the GBM. I ran a model with some basic setup provided with the same data as the more complex RF model. I believe that this model has some more performance in it with more clever tuning, but I would like to share its result anyway in the model selection to compare it to other models. 

# Model selection

For the model selection, it is important to define a loss-function. I assumed the loss function is symmetric and slightly convex meaning, that errors on both sides of our prediction have the same weight, and we are penalizing greater errors more than smaller ones. However, this is a business-related question, so we should cooperate with the company. Because of the above-mentioned points, I have chosen RMSE as a loss-function.

In the table below, we can see the overall prediction performance of each model. Note that these models were trained on the training dataset using 5 fold cross-validation and then evaluated on the holdout dataset. 
 
```{r holdout_rmse_table, echo = FALSE , results = "asis", warning = FALSE, message = FALSE }
library(kableExtra)
result_5 <- cbind(Model = rownames(result_5), result_5)
rownames(result_5) <- 1:nrow(result_5)
kbl(result_5, digits = 2)  %>% kable_styling(bootstrap_options = "striped", full_width = F, position = "center")
```

We can see, that the overall winner is to more complex Random Forest model, and it’s RMSE is significantly better than the other models. However, we can observe, that the GBM is right on the top without any effort put into it, therefore it might worth in the future to try to tune it better. 

As my goal is prediction, I will go on with the best performing model, however, if our client needs interpretation as well, then we can use the model provided by lasso to get a glimpse of the trends. 
Evaluation of the best model (Random Forest)

We have chosen the random forest model according to the RMSE on the holdout dataset, but we can compare the models on the cross-validated averaged RMSE also (see below). It turns out, that the order is the same as before.
TABLE

Furthermore, it is possible to evaluate our final model according to its cross-validated RMSE results (table below). We can see that it has some problems with its robustness as the variance of RMSE is there, but the values are still under the RMSE of other models. 

```{r cv_rmse_table, echo = FALSE , results = "asis", warning = FALSE, message = FALSE }
library(kableExtra)
result_4 <- cbind(Model = rownames(result_4), result_4)
rownames(result_4) <- 1:nrow(result_4)
kbl(result_4, digits = 2) %>% kable_styling(bootstrap_options = "striped", full_width = F, position = "center")
```

In the best RF model the best tuning parameters turned out to be the following (with 54 variables):

- number of vars. at each split = 9
- minimum nodes parameter = 5

# Model diagnostics on the Random Forest Model

### Variable importance

However we can not interpret Random Forest models like OLS, we still have some tools that can explain some details on our “back box” like model. The first one is the variable importance plot that the reader can observe below. The main takeaway from this plot, that the most important variable in our model is the borough in which the apartment is located, after comes the possible number of people, and beds, then some review related variables are important as well.

```{r varimp_plot, fig.width=8,fig.height=4, fig.align='center', echo = FALSE , results = 'asis', warning = FALSE, message = FALSE}
rf_model_2_var_imp_grouped_plot
```

### Partial dependence

Secondly, it worth showing some partial dependence plots, which show how each variable are related to the price. On the first plot, we can observe the number of accommodations, where there is clear tendency. After that, we have a similar plot regarding boroughs.

```{r pdp_n_acc_plot, fig.width=8,fig.height=4, fig.align='center', echo = FALSE , results = 'asis', warning = FALSE, message = FALSE}
pdp_n_acc_plot
```

```{r pdp_n_borough_plot, fig.width=8,fig.height=4,  fig.align='center', echo = FALSE , results = 'asis', warning = FALSE, message = FALSE}
pdp_n_borough_plot
```

### Heterogeneity

```{r geterogeneity_table, echo = FALSE , results = "asis", warning = FALSE, message = FALSE }
kbl(result_4, digits = 2) %>% kable_styling(bootstrap_options = "striped", full_width = F, position = "center")
```


In the table below I collected some outstandingly bad categories regarding the robustness check of my model. The most important column is the last one with the normalized RMSE. It can be seen, that in some boroughs the norm. RMSE is pretty high meaning that my model is not accurate there. It means, that we should expect greater prediction errors in these areas, and if possible we should try to improve there.  


### Prediction

As a final evaluation of the best model let’s see how the model predicts on the holdout dataset. Below it can be seen, that the model mostly overpredict apartments with prices under 100 USD, and the error is getting larger with higher prices. 

```{r pred_plot, fig.width=4,fig.height=4, fig.align='center', echo = FALSE , results = 'asis', warning = FALSE, message = FALSE}
level_vs_pred
```

# Summary:
To conclude I would like the mention, that out of the 5 tested models a Random Forest model turned out to be the best for prediction, however, it is clear that the model has some limitations from the evaluation. To further improve the result, we can provide some more variables according to domain knowledge for example according to the location we can include the distance from the city center or from other frequented places. Compared to the case study using dataset from London, my model on Tokyo is definitely less robust, as it has less observation, but the performance of different kind of models are similar on both datasets. Moreover, it would definitely make the prediction easier if we would have more data that is less affected by the pandemic and a possible Olympic games in the city, but that is Tokyo today. 